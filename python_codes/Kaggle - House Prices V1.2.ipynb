{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train = pd.read_csv(\"../rawdata/train.csv\")\n",
    "test = pd.read_csv(\"../rawdata/test.csv\")\n",
    "\n",
    "x = train.drop([\"SalePrice\", \"Id\"], axis=1).copy()\n",
    "y = train[\"SalePrice\"].copy()\n",
    "\n",
    "x_train_full, x_val_full, y_train, y_val = train_test_split(x, y, train_size=0.8)\n",
    "\n",
    "numerical_cols = [c for c in x_train_full.columns if x_train_full[c].dtype in ['int64', 'float64']]\n",
    "categorical_cols = [c for c in x_train_full.columns if x_train_full[c].dtype=='object']\n",
    "low_cardinality_cols = [c for c in x_val_full.columns if x_val_full[c].nunique()<10 and x_val_full[c].dtype==\"object\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PoolQC          99.657534\n",
       "MiscFeature     96.061644\n",
       "Alley           93.664384\n",
       "Fence           80.907534\n",
       "FireplaceQu     48.287671\n",
       "LotFrontage     17.893836\n",
       "GarageCond       5.736301\n",
       "GarageType       5.736301\n",
       "GarageYrBlt      5.736301\n",
       "GarageFinish     5.736301\n",
       "GarageQual       5.736301\n",
       "BsmtExposure     2.654110\n",
       "BsmtFinType2     2.654110\n",
       "BsmtFinType1     2.568493\n",
       "BsmtCond         2.568493\n",
       "BsmtQual         2.568493\n",
       "MasVnrArea       0.599315\n",
       "MasVnrType       0.599315\n",
       "Electrical       0.085616\n",
       "dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_full.isnull().sum().sort_values(ascending=False)[x_train_full.isnull().sum()>0]/x_train_full.shape[0]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline \"RandomForest\" Model (MVI/One Hot Encoding/GridSearchCV) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "x_train = x_train_full[numerical_cols + low_cardinality_cols].copy()\n",
    "x_val = x_val_full[numerical_cols + low_cardinality_cols].copy()\n",
    "\n",
    "num_imputer = SimpleImputer() #index is included below as it was getting reset in the new dataframe\n",
    "data1_train = pd.DataFrame(num_imputer.fit_transform(x_train[numerical_cols]), index=x_train.index, columns=numerical_cols)\n",
    "data1_val = pd.DataFrame(num_imputer.transform(x_val[numerical_cols]), index=x_val.index, columns=numerical_cols)\n",
    "\n",
    "char_imputer = SimpleImputer(strategy='most_frequent') #index is included below as it was getting reset in the new dataframe\n",
    "data2_train = pd.DataFrame(char_imputer.fit_transform(x_train[low_cardinality_cols]), index=x_train.index, columns=low_cardinality_cols)\n",
    "data2_val = pd.DataFrame(char_imputer.transform(x_val[low_cardinality_cols]), index=x_val.index, columns=low_cardinality_cols)\n",
    "\n",
    "oh_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "data2_train = pd.DataFrame(oh_encoder.fit_transform(data2_train), index=data2_train.index)\n",
    "data2_val = pd.DataFrame(oh_encoder.transform(data2_val), index=data2_val.index)\n",
    "\n",
    "x_train = pd.concat([data1_train, data2_train], axis=1)\n",
    "x_val = pd.concat([data1_val, data2_val], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Random Forest(20%validation data) : 18149.980787671237\n",
      "MAE for Random Forest(5foldCV) : 17710.306232876716\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "rfmodel = RandomForestRegressor()\n",
    "rfmodel.fit(x_train, y_train)\n",
    "predicted = rfmodel.predict(x_val)\n",
    "print(\"MAE for Random Forest(20%validation data) :\",mean_absolute_error(y_val, predicted))\n",
    "\n",
    "x_full = pd.concat([x_train, x_val])\n",
    "y_full = pd.concat([y_train, y_val])\n",
    "scores = -1*cross_val_score(RandomForestRegressor(), x_full, y_full, cv=5, scoring='neg_mean_absolute_error')\n",
    "print(\"MAE for Random Forest(5foldCV) :\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
       "                                             criterion='mse', max_depth=None,\n",
       "                                             max_features='auto',\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             max_samples=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators=100, n_jobs=None,\n",
       "                                             oob_score=False, random_state=None,\n",
       "                                             verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'criterion': ['mae'], 'max_depth': [4, 5, 6, 7, 8],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'n_estimators': [50, 75, 100, 125, 150, 200]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators' : [50, 75, 100, 125, 150, 200],\n",
    "    'criterion' : ['mae'],\n",
    "    'max_depth' : [4, 5, 6, 7, 8],\n",
    "    'max_features' : ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "rfreg = RandomForestRegressor()\n",
    "\n",
    "cv_rfreg = GridSearchCV(estimator=rfreg, param_grid=param_grid, cv=5)\n",
    "cv_rfreg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'mae',\n",
       " 'max_depth': 8,\n",
       " 'max_features': 'auto',\n",
       " 'n_estimators': 50}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_rfreg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_p1 = pd.DataFrame(num_imputer.transform(test[numerical_cols]), index=test.index, columns=numerical_cols)\n",
    "test_p2 = pd.DataFrame(char_imputer.transform(test[low_cardinality_cols]), index=test.index, columns=low_cardinality_cols)\n",
    "test_p2 = pd.DataFrame(oh_encoder.transform(test_p2), index=test_p2.index)\n",
    "test_v2 = pd.concat([test_p1, test_p2], axis=1)\n",
    "\n",
    "test_pred = cv_rfreg.best_estimator_.predict(test_v2)\n",
    "submission = pd.DataFrame({\"Id\" : test.Id,\n",
    "                          \"SalePrice\" : test_pred})\n",
    "submission.to_csv(\"../rawdata/submission_v1n2.csv\", index=False)\n",
    "#Kaggle Score : 0.15692"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline \"XGBoost\" Model (MVI/One Hot Encoding/GridSearchCV) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for xgb(20%validation data) : 17424.220756635274\n",
      "MAE for xgb(5foldCV) : 16353.975989940067\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgbmodel = XGBRegressor(objective='reg:squarederror')\n",
    "xgbmodel.fit(x_train, y_train)\n",
    "predicted = xgbmodel.predict(x_val)\n",
    "print(\"MAE for xgb(20%validation data) :\",mean_absolute_error(y_val, predicted))\n",
    "\n",
    "x_full = pd.concat([x_train, x_val])\n",
    "y_full = pd.concat([y_train, y_val])\n",
    "scores = -1*cross_val_score(XGBRegressor(objective='reg:squarederror'), x_full, y_full, cv=5, scoring='neg_mean_absolute_error')\n",
    "print(\"MAE for xgb(5foldCV) :\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                                    colsample_bylevel=1, colsample_bynode=1,\n",
       "                                    colsample_bytree=1, gamma=0,\n",
       "                                    importance_type='gain', learning_rate=0.1,\n",
       "                                    max_delta_step=0, max_depth=3,\n",
       "                                    min_child_weight=1, missing=None,\n",
       "                                    n_estimators=100, n_jobs=1, nthread=None,\n",
       "                                    objective='reg:linear', random_state=0,\n",
       "                                    reg_alpha=0, reg_lambda=1,\n",
       "                                    scale_pos_weight=1, seed=None, silent=None,\n",
       "                                    subsample=1, verbosity=1),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'learning_rate': [0.05, 0.1],\n",
       "                         'max_depth': [3, 4, 5, 6],\n",
       "                         'n_estimators': [50, 75, 100, 150], 'n_jobs': [3],\n",
       "                         'objective': ['reg:squarederror']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators' : [50, 75, 100, 150],\n",
    "    'max_depth' : [3, 4, 5, 6],\n",
    "    'learning_rate' : [.05, .1],\n",
    "    'objective' : ['reg:squarederror'],\n",
    "    'n_jobs' : [3]    \n",
    "}\n",
    "\n",
    "xgbmodel = XGBRegressor()\n",
    "\n",
    "cv_xgb = GridSearchCV(estimator=xgbmodel, param_grid=param_grid, cv=5)\n",
    "cv_xgb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.05,\n",
       " 'max_depth': 6,\n",
       " 'n_estimators': 150,\n",
       " 'n_jobs': 3,\n",
       " 'objective': 'reg:squarederror'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for xgb(gridsearchcv) : 17199.011584974316\n"
     ]
    }
   ],
   "source": [
    "predicted = cv_xgb.best_estimator_.predict(x_val)\n",
    "print(\"MAE for xgb(gridsearchcv) :\",mean_absolute_error(y_val, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_p1 = pd.DataFrame(num_imputer.transform(test[numerical_cols]), index=test.index, columns=numerical_cols)\n",
    "test_p2 = pd.DataFrame(char_imputer.transform(test[low_cardinality_cols]), index=test.index, columns=low_cardinality_cols)\n",
    "test_p2 = pd.DataFrame(oh_encoder.transform(test_p2), index=test_p2.index)\n",
    "test_v2 = pd.concat([test_p1, test_p2], axis=1)\n",
    "\n",
    "test_pred = cv_xgb.best_estimator_.predict(test_v2)\n",
    "submission = pd.DataFrame({\"Id\" : test.Id,\n",
    "                          \"SalePrice\" : test_pred})\n",
    "submission.to_csv(\"../rawdata/submission_v1n2(2).csv\", index=False)\n",
    "#Kaggle Rank : 2618/5099 (Score : 0.13876)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline \"LightGBM\" model (MVI/No Encoding/GridSearchCV):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train_full[numerical_cols + categorical_cols].copy()\n",
    "x_val = x_val_full[numerical_cols + categorical_cols].copy()\n",
    "\n",
    "num_imputer = SimpleImputer() #index is included below as it was getting reset in the new dataframe\n",
    "data1_train = pd.DataFrame(num_imputer.fit_transform(x_train[numerical_cols]), index=x_train.index, columns=numerical_cols)\n",
    "data1_val = pd.DataFrame(num_imputer.transform(x_val[numerical_cols]), index=x_val.index, columns=numerical_cols)\n",
    "\n",
    "char_imputer = SimpleImputer(strategy='most_frequent') #index is included below as it was getting reset in the new dataframe\n",
    "data2_train = pd.DataFrame(char_imputer.fit_transform(x_train[categorical_cols]), index=x_train.index, columns=categorical_cols)\n",
    "data2_val = pd.DataFrame(char_imputer.transform(x_val[categorical_cols]), index=x_val.index, columns=categorical_cols)\n",
    "\n",
    "x_train = pd.concat([data1_train, data2_train], axis=1)\n",
    "x_val = pd.concat([data1_val, data2_val], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's mape: 0.258664\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's mape: 0.23897\n",
      "[3]\tvalid_0's mape: 0.221476\n",
      "[4]\tvalid_0's mape: 0.206401\n",
      "[5]\tvalid_0's mape: 0.19533\n",
      "[6]\tvalid_0's mape: 0.184278\n",
      "[7]\tvalid_0's mape: 0.175184\n",
      "[8]\tvalid_0's mape: 0.167298\n",
      "[9]\tvalid_0's mape: 0.158971\n",
      "[10]\tvalid_0's mape: 0.15144\n",
      "[11]\tvalid_0's mape: 0.145381\n",
      "[12]\tvalid_0's mape: 0.139351\n",
      "[13]\tvalid_0's mape: 0.134357\n",
      "[14]\tvalid_0's mape: 0.130369\n",
      "[15]\tvalid_0's mape: 0.126256\n",
      "[16]\tvalid_0's mape: 0.122518\n",
      "[17]\tvalid_0's mape: 0.119654\n",
      "[18]\tvalid_0's mape: 0.117447\n",
      "[19]\tvalid_0's mape: 0.115606\n",
      "[20]\tvalid_0's mape: 0.11349\n",
      "[21]\tvalid_0's mape: 0.111842\n",
      "[22]\tvalid_0's mape: 0.110432\n",
      "[23]\tvalid_0's mape: 0.109263\n",
      "[24]\tvalid_0's mape: 0.108022\n",
      "[25]\tvalid_0's mape: 0.107098\n",
      "[26]\tvalid_0's mape: 0.105714\n",
      "[27]\tvalid_0's mape: 0.105039\n",
      "[28]\tvalid_0's mape: 0.104249\n",
      "[29]\tvalid_0's mape: 0.103229\n",
      "[30]\tvalid_0's mape: 0.102157\n",
      "[31]\tvalid_0's mape: 0.10176\n",
      "[32]\tvalid_0's mape: 0.100818\n",
      "[33]\tvalid_0's mape: 0.0999674\n",
      "[34]\tvalid_0's mape: 0.0997627\n",
      "[35]\tvalid_0's mape: 0.0989655\n",
      "[36]\tvalid_0's mape: 0.098418\n",
      "[37]\tvalid_0's mape: 0.098228\n",
      "[38]\tvalid_0's mape: 0.0974982\n",
      "[39]\tvalid_0's mape: 0.0972927\n",
      "[40]\tvalid_0's mape: 0.0969965\n",
      "[41]\tvalid_0's mape: 0.0967795\n",
      "[42]\tvalid_0's mape: 0.0965526\n",
      "[43]\tvalid_0's mape: 0.0962453\n",
      "[44]\tvalid_0's mape: 0.0960983\n",
      "[45]\tvalid_0's mape: 0.0959806\n",
      "[46]\tvalid_0's mape: 0.0959077\n",
      "[47]\tvalid_0's mape: 0.0955358\n",
      "[48]\tvalid_0's mape: 0.0952126\n",
      "[49]\tvalid_0's mape: 0.0951527\n",
      "[50]\tvalid_0's mape: 0.0950129\n",
      "[51]\tvalid_0's mape: 0.0947487\n",
      "[52]\tvalid_0's mape: 0.0946224\n",
      "[53]\tvalid_0's mape: 0.0944708\n",
      "[54]\tvalid_0's mape: 0.0942189\n",
      "[55]\tvalid_0's mape: 0.0939998\n",
      "[56]\tvalid_0's mape: 0.0939275\n",
      "[57]\tvalid_0's mape: 0.0938736\n",
      "[58]\tvalid_0's mape: 0.0938075\n",
      "[59]\tvalid_0's mape: 0.0937711\n",
      "[60]\tvalid_0's mape: 0.0935663\n",
      "[61]\tvalid_0's mape: 0.0935625\n",
      "[62]\tvalid_0's mape: 0.0935205\n",
      "[63]\tvalid_0's mape: 0.0932903\n",
      "[64]\tvalid_0's mape: 0.0933365\n",
      "[65]\tvalid_0's mape: 0.0932431\n",
      "[66]\tvalid_0's mape: 0.09329\n",
      "[67]\tvalid_0's mape: 0.0931374\n",
      "[68]\tvalid_0's mape: 0.0930747\n",
      "[69]\tvalid_0's mape: 0.093066\n",
      "[70]\tvalid_0's mape: 0.0929948\n",
      "[71]\tvalid_0's mape: 0.0928524\n",
      "[72]\tvalid_0's mape: 0.0928142\n",
      "[73]\tvalid_0's mape: 0.0927908\n",
      "[74]\tvalid_0's mape: 0.0927848\n",
      "[75]\tvalid_0's mape: 0.0927562\n",
      "[76]\tvalid_0's mape: 0.0927267\n",
      "[77]\tvalid_0's mape: 0.0927293\n",
      "[78]\tvalid_0's mape: 0.0926761\n",
      "[79]\tvalid_0's mape: 0.0927352\n",
      "[80]\tvalid_0's mape: 0.0926871\n",
      "[81]\tvalid_0's mape: 0.092682\n",
      "[82]\tvalid_0's mape: 0.092666\n",
      "[83]\tvalid_0's mape: 0.0927365\n",
      "[84]\tvalid_0's mape: 0.0926649\n",
      "[85]\tvalid_0's mape: 0.0926863\n",
      "[86]\tvalid_0's mape: 0.0926554\n",
      "[87]\tvalid_0's mape: 0.0925872\n",
      "[88]\tvalid_0's mape: 0.0926261\n",
      "[89]\tvalid_0's mape: 0.0926102\n",
      "[90]\tvalid_0's mape: 0.0926096\n",
      "[91]\tvalid_0's mape: 0.0926017\n",
      "[92]\tvalid_0's mape: 0.092598\n",
      "[93]\tvalid_0's mape: 0.0926636\n",
      "[94]\tvalid_0's mape: 0.0926698\n",
      "[95]\tvalid_0's mape: 0.0926945\n",
      "[96]\tvalid_0's mape: 0.0926572\n",
      "[97]\tvalid_0's mape: 0.0926243\n",
      "Early stopping, best iteration is:\n",
      "[87]\tvalid_0's mape: 0.0925872\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "for c in categorical_cols:\n",
    "    x_train[c]=x_train[c].astype('category')\n",
    "    x_val[c]=x_val[c].astype('category')\n",
    "\n",
    "lgb_train = lgb.Dataset(x_train, label=y_train)\n",
    "lgb_val = lgb.Dataset(x_val, label=y_val)\n",
    "\n",
    "lparam = {'objective':'mape', 'min_data_in_leaf':30}\n",
    "\n",
    "lgbmodel = lgb.train(params=lparam, train_set=lgb_train, num_boost_round=1000, valid_sets=lgb_val, early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_p1 = pd.DataFrame(num_imputer.transform(test[numerical_cols]), index=test.index, columns=numerical_cols)\n",
    "test_p2 = pd.DataFrame(char_imputer.transform(test[categorical_cols]), index=test.index, columns=categorical_cols)\n",
    "test_v3 = pd.concat([test_p1, test_p2], axis=1)\n",
    "\n",
    "for c in categorical_cols:\n",
    "    test_v3[c]=test_v3[c].astype('category')\n",
    "\n",
    "test_pred = lgbmodel.predict(test_v3[numerical_cols + categorical_cols])\n",
    "submission = pd.DataFrame({\"Id\" : test.Id,\n",
    "                          \"SalePrice\" : test_pred})\n",
    "submission.to_csv(\"../rawdata/submission_v1n2(3).csv\", index=False)\n",
    "#Kaggle Score : 0.14571"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Encoding / Target Encoding / Catboost Encoding in \"LightGBM\" :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\kaggle_py3p7\\lib\\site-packages\\category_encoders\\count.py:255: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  X.loc[:, self.cols] = X.fillna(value=pd.np.nan)\n"
     ]
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "x_train = x_train_full[numerical_cols + categorical_cols].copy()\n",
    "x_val = x_val_full[numerical_cols + categorical_cols].copy()\n",
    "\n",
    "num_imputer = SimpleImputer() #index is included below as it was getting reset in the new dataframe\n",
    "data1_train = pd.DataFrame(num_imputer.fit_transform(x_train[numerical_cols]), index=x_train.index, columns=numerical_cols)\n",
    "data1_val = pd.DataFrame(num_imputer.transform(x_val[numerical_cols]), index=x_val.index, columns=numerical_cols)\n",
    "\n",
    "char_imputer = SimpleImputer(strategy='most_frequent') #index is included below as it was getting reset in the new dataframe\n",
    "data2_train = pd.DataFrame(char_imputer.fit_transform(x_train[categorical_cols]), index=x_train.index, columns=categorical_cols)\n",
    "data2_val = pd.DataFrame(char_imputer.transform(x_val[categorical_cols]), index=x_val.index, columns=categorical_cols)\n",
    "\n",
    "x_train_temp = pd.concat([data1_train, data2_train], axis=1)\n",
    "x_val_temp = pd.concat([data1_val, data2_val], axis=1)\n",
    "\n",
    "count_enc = ce.CountEncoder()\n",
    "train_ce = count_enc.fit_transform(data2_train).add_suffix('_count')\n",
    "val_ce = count_enc.transform(data2_val).add_suffix('_count')\n",
    "x_train1 = data1_train.join(train_ce)\n",
    "x_val1 = data1_val.join(val_ce)\n",
    "\n",
    "target_enc = ce.TargetEncoder()\n",
    "train_te = target_enc.fit_transform(data2_train, y_train).add_suffix('_target')\n",
    "val_te = target_enc.transform(data2_val).add_suffix('_target')\n",
    "x_train2 = data1_train.join(train_te)\n",
    "x_val2 = data1_val.join(val_te)\n",
    "\n",
    "targecb_enc = ce.CatBoostEncoder()\n",
    "train_cbe = targecb_enc.fit_transform(data2_train, y_train).add_suffix('_targetcb')\n",
    "val_cbe = targecb_enc.transform(data2_val).add_suffix('_targetcb')\n",
    "x_train3 = data1_train.join(train_cbe)\n",
    "x_val3 = data1_val.join(val_cbe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\kaggle_py3p7\\lib\\site-packages\\category_encoders\\count.py:255: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  X.loc[:, self.cols] = X.fillna(value=pd.np.nan)\n"
     ]
    }
   ],
   "source": [
    "lgb_train1 = lgb.Dataset(x_train1, label=y_train)\n",
    "lgb_train2 = lgb.Dataset(x_train2, label=y_train)\n",
    "lgb_train3 = lgb.Dataset(x_train3, label=y_train)\n",
    "lgb_val1 = lgb.Dataset(x_val1, label=y_val)\n",
    "lgb_val2 = lgb.Dataset(x_val2, label=y_val)\n",
    "lgb_val3 = lgb.Dataset(x_val3, label=y_val)\n",
    "\n",
    "lparam = {'objective':'mape', 'min_data_in_leaf':30}\n",
    "\n",
    "lgbmodel1 = lgb.train(params=lparam, train_set=lgb_train1, num_boost_round=1000, valid_sets=lgb_val1,\n",
    "                     early_stopping_rounds=10, verbose_eval=False)\n",
    "lgbmodel2 = lgb.train(params=lparam, train_set=lgb_train2, num_boost_round=1000, valid_sets=lgb_val2,\n",
    "                     early_stopping_rounds=10, verbose_eval=False)\n",
    "lgbmodel3 = lgb.train(params=lparam, train_set=lgb_train3, num_boost_round=1000, valid_sets=lgb_val3,\n",
    "                     early_stopping_rounds=10, verbose_eval=False)\n",
    "\n",
    "test_p1 = pd.DataFrame(num_imputer.transform(test[numerical_cols]), index=test.index, columns=numerical_cols)\n",
    "test_p2 = pd.DataFrame(char_imputer.transform(test[categorical_cols]), index=test.index, columns=categorical_cols)\n",
    "test_temp = pd.concat([test_p1, test_p2], axis=1)\n",
    "test_ce = count_enc.transform(test_p2).add_suffix('_count')\n",
    "test_te = target_enc.transform(test_p2).add_suffix('_target')\n",
    "test_cbe = targecb_enc.transform(test_p2).add_suffix('_targetcb')\n",
    "test_v4 = test_p1.join(test_ce)\n",
    "test_v5 = test_p1.join(test_te)\n",
    "test_v6 = test_p1.join(test_cbe)\n",
    "\n",
    "test_pred4 = lgbmodel1.predict(test_v4)\n",
    "test_pred5 = lgbmodel2.predict(test_v5)\n",
    "test_pred6 = lgbmodel3.predict(test_v6)\n",
    "\n",
    "submission1 = pd.DataFrame({\"Id\" : test.Id, \"SalePrice\" : test_pred4})\n",
    "submission2 = pd.DataFrame({\"Id\" : test.Id, \"SalePrice\" : test_pred5})\n",
    "submission3 = pd.DataFrame({\"Id\" : test.Id, \"SalePrice\" : test_pred6})\n",
    "submission1.to_csv(\"../rawdata/submission_v1n2(4).csv\", index=False)\n",
    "#Kaggle Score : 0.14389\n",
    "submission2.to_csv(\"../rawdata/submission_v1n2(5).csv\", index=False)\n",
    "#Kaggle Score : 0.14579\n",
    "submission3.to_csv(\"../rawdata/submission_v1n2(6).csv\", index=False)\n",
    "#Kaggle Score : 0.14623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
